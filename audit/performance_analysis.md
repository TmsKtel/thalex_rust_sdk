# Анализ производительности и узких мест

## Выявленные узкие места

### 1. Блокировки Mutex в горячих путях

**Проблема:**
- В функции `handle_incoming` (строка 334-373) происходит блокировка Mutex для каждого входящего сообщения
- Это критический путь, так как все сообщения проходят через эту функцию
- При высокой частоте сообщений (например, ticker с задержкой 100ms) блокировки могут создавать очередь

**Локации:**
- `handle_incoming`: строки 349, 360 - блокировки для доступа к `pending_requests` и `subscriptions`
- `call_rpc`: строки 81, 98 - блокировки при добавлении/удалении запросов
- `subscribe/unsubscribe`: строки 121, 149 - блокировки при управлении подписками

**Влияние:**
- Задержка обработки каждого сообщения из-за ожидания блокировки
- Потенциальная деградация при большом количестве одновременных RPC запросов
- Конкуренция между обработкой входящих сообщений и управлением подписками

### 2. Избыточное клонирование строк

**Проблема:**
- В `subscribe` (строка 115): `channel.to_string()` создает новую строку
- В `handle_incoming` (строка 335): `text: String` принимается по значению, но затем передается дальше
- В `run_single_connection` (строка 264): `msg.to_string()` создает строку для каждого канала при переподключении
- В `connection_supervisor` (строка 218): создается новая строка для каждого failed запроса

**Влияние:**
- Лишние аллокации памяти
- Копирование данных вместо перемещения
- Дополнительная нагрузка на GC (хотя в Rust нет GC, но аллокации все равно дорогие)

### 3. JSON парсинг на каждое сообщение

**Проблема:**
- В `handle_incoming` (строка 339) каждый входящий текст парсится в `serde_json::Value`
- Даже если сообщение не требует полного парсинга (например, нужно только проверить наличие поля "id" или "channel_name")

**Влияние:**
- Парсинг JSON - CPU-интенсивная операция
- При высокой частоте сообщений это может стать узким местом
- Избыточный парсинг, если нужны только определенные поля

### 4. HashMap операции в критическом пути

**Проблема:**
- Поиск в HashMap под блокировкой для каждого сообщения
- При большом количестве подписок или pending запросов поиск может замедляться
- Использование `String` как ключа требует хеширования строки

**Влияние:**
- O(1) в среднем, но может деградировать при коллизиях
- Хеширование строк - относительно дорогая операция

### 5. Отсутствие батчинга при переподписке

**Проблема:**
- В `run_single_connection` (строки 257-266) при переподключении отправляется отдельное сообщение для каждого канала
- Можно было бы отправить одну команду с массивом всех каналов

**Влияние:**
- Больше сетевых round-trips
- Больше сериализации JSON
- Медленнее восстановление подписок

### 6. Фиксированная задержка переподключения

**Проблема:**
- В `connection_supervisor` (строки 232, 239) используется фиксированная задержка 3 секунды
- Нет экспоненциального backoff
- Нет jitter для предотвращения thundering herd

**Влияние:**
- При проблемах с сетью может создавать излишнюю нагрузку
- Медленнее восстановление при временных проблемах

### 7. Создание отдельной задачи для каждого callback

**Проблема:**
- В `subscribe` (строка 135) для каждой подписки создается отдельная tokio задача
- При большом количестве подписок это создает много задач

**Влияние:**
- Дополнительный overhead на управление задачами
- Больше контекстных переключений

### 8. Отсутствие пула для переиспользования буферов

**Проблема:**
- Каждое сообщение создает новые строки и буферы
- Нет переиспользования памяти

**Влияние:**
- Больше аллокаций
- Больше pressure на аллокатор

## Метрики для измерения

Рекомендуется добавить метрики для:
1. Время удержания блокировок Mutex
2. Количество сообщений в секунду
3. Задержка обработки сообщений (latency)
4. Количество аллокаций
5. CPU usage при высокой нагрузке

## Приоритеты оптимизации

### Высокий приоритет:
1. Оптимизация блокировок в `handle_incoming` (использование RwLock или lock-free структур)
2. Батчинг переподписок при переподключении
3. Оптимизация JSON парсинга (lazy parsing или streaming parser)

### Средний приоритет:
4. Уменьшение клонирования строк
5. Экспоненциальный backoff для переподключения
6. Использование более эффективных структур данных (например, `DashMap` для concurrent access)

### Низкий приоритет:
7. Пул буферов
8. Оптимизация управления задачами для callbacks

